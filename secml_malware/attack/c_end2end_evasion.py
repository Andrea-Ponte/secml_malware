"""
.. module:: CMalConvAttackEvasion
	:synopsis: Class performs evasion attacks against malconv classifier, under different constraints.

.. moduleauthor:: Luca Demetrio <luca.demetrio@dibris.unige.it>

"""
import copy
import struct

import numpy as np
import torch

from secml.adv.attacks import CAttackEvasion
from secml.array import CArray
from secml.array.c_dense import CDense
from secml.data import CDataset
from secml.optim.constraints import CConstraint
from secml.optim.function import CFunction
from secml.optim.optimizers import COptimizer
from secml.settings import SECML_PYTORCH_USE_CUDA
from secml_malware.utils.extend_pe import apply_shift_to_raw_code

from secml_malware.models import CClassifierEnd2EndMalware

use_cuda = torch.cuda.is_available() and SECML_PYTORCH_USE_CUDA

def gradient_search(
	start_byte: int,
	gradient: torch.Tensor,
	embedding_bytes: torch.Tensor,
	invalid_val=np.infty,
	invalid_pos=-1,
):
	"""Given the starting byte, the gradient and the embedding map,
	it returns a list of distances

	Arguments:
		start_byte {int} -- the byte that is used for searching the fittest one.
		gradient {ndarray} -- An array containing the gradient computed in start_byte
		embedding_bytes {ndarray} -- a matrix containing all the embeddings

	Keyword Arguments:
		invalid_val {[type]} -- Value used for indexes that are discrded during the process (default: {np.infty})
		invalid_pos {int} -- Index of invalid value, that is the index 256 (default: {-1})

	Returns:
		list -- matrix of distances
	"""
	distance = []
	if torch.equal(gradient, torch.zeros(gradient.shape)):
		return [invalid_val] * len(embedding_bytes)
	start_emb_byte = embedding_bytes[start_byte]
	for b in embedding_bytes:
		bts = b - start_emb_byte
		gs = -gradient / torch.norm(gradient)
		s_i = torch.dot(gs, bts)
		if s_i <= 0:
			distance.append(invalid_val)
			continue
		d_i = torch.norm(b - (start_emb_byte + s_i * (-gradient)))
		distance.append(d_i)
	distance[invalid_pos] = invalid_val
	distance = torch.Tensor(distance)
	if use_cuda:
		distance = distance.cuda()
	return distance


class CEnd2EndMalwareEvasion(CAttackEvasion):
	def _objective_function_gradient(self, x):
		pass

	def _objective_function(self, x):
		pass

	def __init__(
		self,
		end2end_model: CClassifierEnd2EndMalware,
		indexes_to_perturb: list,
		how_many: int,
		surrogate_data: CDataset,
		surrogate_classifier: CClassifierEnd2EndMalware = None,
		use_surrogate: bool = False,
		iterations: int = 1e2,
		is_debug: bool = False,
		random_init: bool = False,
		chunk_optimization: bool = False,
		dos_optimization: bool = False,
	):
		CAttackEvasion.__init__(
			self,
			end2end_model,
			end2end_model if surrogate_classifier is None else surrogate_classifier,
			surrogate_data=surrogate_data,
			y_target=None,
		)
		self._iterations = iterations
		self.is_debug = is_debug
		self.indexes_to_perturb = indexes_to_perturb
		self._how_many = how_many
		self.confidences_ = []
		self.changes_per_iterations_ = []
		self.use_surrogate = use_surrogate
		self.random_init = random_init

		self.embedding_size = end2end_model.get_embedding_size()
		self.max_input_length = end2end_model.get_input_max_length()
		self.invalid_pos = end2end_model.get_embedding_value()
		self.embedding_value = end2end_model.get_embedding_value()
		self.shift_values = end2end_model.get_is_shifting_values()

		self.chunk_optimization = chunk_optimization
		self.optimize_all_dos = dos_optimization

		self._invalid_value = torch.Tensor([np.infty])

	def _extract_window_gradient(self, gradient_f):
		"""
		Determine which components should be considered for the attack.
		Args:
			gradient_f {ndarray} -- the gradient computed on all input

		Returns:
			a list of indexes to perturb
		"""
		return (
			gradient_f[self.indexes_to_perturb, :]
			.norm(dim=-1)
			.argsort(descending=True)[: self._how_many]
			.tolist()
		)

	def _run(self, x0, y0, x_init=None):
		"""
		Tries to achieve evasion against MalConv.
		Parameters
		----------
		x0 : CArray
			Initial sample.
		y0 : int or CArray
			The true label of x0.
		x_init : CArray or None, optional
			Initialization point. If None, it is set to x0.
		Returns
		-------
		x_opt : CArray
			Evasion sample
		f_opt : float
			Value of objective function on x_opt.
		Notes
		-----
		Internally, it stores the confidences and how many iterations have been applied at each round.
		"""
		self._init_internal_solver(x0)
		if self.optimize_all_dos:
			pe_position = x_init[0x3C:0x40].tolist()[0]
			if self.shift_values:
				pe_position = [p - 1 for p in pe_position]
			pe_position = struct.unpack("<I", bytes(pe_position))[0]
			self.indexes_to_perturb = [i for i in range(2, 0x3C)] + [
				i for i in range(0x40, pe_position)
			]
			self._how_many = len(self.indexes_to_perturb)
			if self.is_debug:
				print(f"PE POSITION: {pe_position}, perturbing {self._how_many}")
		if x_init is None:
			x_init = copy.copy(x0)
		self.changes_per_iterations_ = []
		self.confidences_ = []
		t = self._iterations
		predict_fun = self._get_predict_function()
		_, current_conf = predict_fun(x_init, return_decision_function=True)
		current_conf = current_conf[1].item()

		if use_cuda:
			self._invalid_value = self._invalid_value.cuda()
		E = self.classifier.embed(
			np.array([[i if i < 256 else 256 for i in range(self.max_input_length)]]),
			transpose=False,
		)[0][:257]
		if self.random_init:
			min_val = 0 + self.shift_values
			max_val = 255 + self.shift_values
			x_init[self.indexes_to_perturb] = CDense(
				torch.randint(
					low=min_val, high=max_val, size=(1, len(self.indexes_to_perturb))
				)
			)
		if self.is_debug:
			print("> Beginning new sample evasion...")
		classifier = (
			self.surrogate_classifier if self.use_surrogate else self.classifier
		)
		gradient_f = classifier.compute_embedding_gradient(x_init)
		index_to_consider = np.array(self.indexes_to_perturb)[
			self._extract_window_gradient(gradient_f)
		]

		while t and current_conf > 0.5:
			how_many_invalid = 0
			gradient_f = classifier.compute_embedding_gradient(x_init)

			for i in index_to_consider:
				gradient_f_i = gradient_f[i]
				x_i = x_init[i].tondarray().ravel().item()
				distances = gradient_search(
					x_i,
					gradient_f_i,
					E,
					invalid_val=self._invalid_value,
					invalid_pos=self.invalid_pos,
				)
				_, byte_to_choose = torch.min(distances, dim=0)
				if not torch.equal(distances[byte_to_choose], self._invalid_value):
					x_init[i] = byte_to_choose.item()

			self.changes_per_iterations_.append(
				len(self.indexes_to_perturb) - how_many_invalid
			)
			_, current_conf = predict_fun(x_init, return_decision_function=True)
			current_conf = current_conf[1].item()
			self.confidences_.append(current_conf)
			t = t - 1
			if self.is_debug:
				print(f">{t}/{self._iterations} Shifted confidence:\t{current_conf}")
				print(f" Invalid {how_many_invalid}/{self._how_many}")
			if how_many_invalid == len(self.indexes_to_perturb):
				break
		return x_init, current_conf

	def _get_predict_function(self):
		predict_fun = (
			self.surrogate_classifier.predict
			if self.use_surrogate
			else self.classifier.predict
		)
		return predict_fun

	def _init_internal_solver(self, x0):
		fun = CFunction(
			fun=self._objective_function,
			gradient=self._objective_function_gradient,
			n_dim=self.n_dim,
		)
		constraint = CConstraint.create("l1")
		constraint.center = x0
		constraint.radius = 0
		lb = self._x0.todense() if self.lb == "x0" else self.lb
		ub = self._x0.todense() if self.ub == "x0" else self.ub
		bounds = CConstraint.create("box", lb=lb, ub=ub)
		self._solver = COptimizer.create(
			"pgd-ls", fun=fun, constr=constraint, bounds=bounds, discrete=True
		)

	def create_real_sample_from_adv(self, original_file_path : str, x_adv : CArray, new_file_path : str, shift_sample_amount : None):
		with open(original_file_path, 'rb') as f:
			code = bytearray(f.read())
		if shift_sample_amount is not None:
			code = apply_shift_to_raw_code(shift_sample_amount, code, None)
		if self.shift_values:
			x_adv = x_adv - 1
		x_adv = x_adv.tolist()
		x_adv = b''.join([bytes([i]) for i in x_adv])
		code[:len(x_adv)] = x_adv
		with open(new_file_path, 'wb') as f:
			f.write(code)
