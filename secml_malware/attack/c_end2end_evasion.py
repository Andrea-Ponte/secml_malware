"""
.. module:: CMalConvAttackEvasion
	:synopsis: Class performs evasion attacks against malconv classifier, under different constraints.

.. moduleauthor:: Luca Demetrio <luca.demetrio@dibris.unige.it>

"""
import copy
import struct
from abc import abstractmethod

import numpy as np
import torch

from joblib import Parallel, delayed

from secml.adv.attacks import CAttackEvasion
from secml.array import CArray
from secml.array.c_dense import CDense
from secml.data import CDataset
from secml.optim.constraints import CConstraint
from secml.optim.function import CFunction
from secml.optim.optimizers import COptimizer
from secml.settings import SECML_PYTORCH_USE_CUDA
from secml_malware.utils.extend_pe import apply_shift_to_raw_code

from secml_malware.models import CClassifierEnd2EndMalware

use_cuda = torch.cuda.is_available() and SECML_PYTORCH_USE_CUDA


class CEnd2EndMalwareEvasion(CAttackEvasion):
	def _objective_function_gradient(self, x):
		pass

	def _objective_function(self, x):
		pass

	def __init__(
		self,
		end2end_model: CClassifierEnd2EndMalware,
		indexes_to_perturb: list,
		iterations: int = 100,
		is_debug: bool = False,
		random_init: bool = False,
		threshold : float = 0.5,
		penalty_regularizer : float = 0,
		invalid_byte_value : int = 256
	):
		CAttackEvasion.__init__(
			self,
			end2end_model,
			end2end_model,
			surrogate_data=CDataset(CArray([[0], [1]]), CArray([0, 1])),
			y_target=None,
		)
		self.iterations = iterations
		self.is_debug = is_debug
		self.indexes_to_perturb = indexes_to_perturb
		self.confidences_ = []
		self.changes_per_iterations_ = []

		self.random_init = random_init

		self.embedding_size = end2end_model.get_embedding_size()
		self.max_input_length = end2end_model.get_input_max_length()
		self.invalid_pos = end2end_model.get_embedding_value()
		self.embedding_value = end2end_model.get_embedding_value()
		self.shift_values = end2end_model.get_is_shifting_values()

		self._invalid_value = torch.tensor([np.infty])

		self.threshold = threshold
		self.penalty_regularizer = penalty_regularizer

	@abstractmethod
	def loss_function_gradient(self, original_x : CArray, adv_x : CArray, penalty_term : torch.Tensor):
		raise NotImplementedError("This is only an abstract method")

	def _run(self, x0, y0, x_init=None):
		"""
		Tries to achieve evasion against and end-to-end classifier.
		Parameters
		----------
		x0 : CArray
			Initial sample.
		y0 : int or CArray
			The true label of x0.
		x_init : CArray or None, optional
			Initialization point. If None, it is set to x0.
		Returns
		-------
		x_opt : CArray
			Evasion sample
		f_opt : float
			Value of objective function on x_opt.
		Notes
		-----
		Internally, it stores the confidences at each round.
		"""
		self._init_internal_solver(x0)

		if x_init is None:
			x_init = copy.copy(x0)

		_, current_conf = self.classifier.predict(x_init, return_decision_function=True)
		current_conf = current_conf[1].item()
		self.confidences_ = [current_conf]

		if self.is_debug:
			print(f'> Original Confidence: {current_conf}')

		if use_cuda:
			self._invalid_value = self._invalid_value.cuda()

		E = self.get_embedded_byte_matrix()
		if self.random_init:
			x_init = self.randomize_values_for_attack(x_init)

		if self.is_debug:
			print("> Beginning new sample evasion...")

		index_to_consider = np.array(self.indexes_to_perturb)
		x_init = self.apply_feature_mapping(x_init)
		for t in range(self.iterations):
			if current_conf < self.threshold:
				print(f"Stopped at confidence below threshold: {current_conf}/{self.threshold}")
				break

			penalty_term = self.compute_penalty_term(x0, x_init, self.penalty_regularizer)
			gradient_f = self.loss_function_gradient(x0, x_init, penalty_term)
			x_init = self.optimization_solver(E, gradient_f, index_to_consider, x_init)
			current_conf = self.infer_step(x_init)

			self.confidences_.append(current_conf)
			if self.is_debug:
				print(f">{t}/{self.iterations} Shifted confidence:\t{current_conf}")

		x_init = self.invert_feature_mapping(x0, x_init)
		_, current_conf = self.classifier.predict(x_init, return_decision_function=True)
		current_conf = current_conf[1].item()
		if self.is_debug:
			print(f'>AFTER INVERSION, CONFIDENCE SCORE: {current_conf}')
		return x_init, current_conf

	def get_embedded_byte_matrix(self):
		return self.classifier.embed(
			np.array([[i if i < 256 else 256 for i in range(self.max_input_length)]]),
			transpose=False,
		)[0][:257]

	@abstractmethod
	def apply_feature_mapping(self, x):
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")

	@abstractmethod
	def invert_feature_mapping(self, x, x_adv):
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")

	@abstractmethod
	def infer_step(self, x_init):
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")

	def randomize_values_for_attack(self, x_init):
		min_val = 0 + self.shift_values
		max_val = 255 + self.shift_values
		x_init[self.indexes_to_perturb] = CDense(
			torch.randint(
				low=min_val, high=max_val, size=(1, len(self.indexes_to_perturb))
			)
		)
		return x_init

	@abstractmethod
	def compute_penalty_term(self, original_x: CArray, adv_x: CArray, par: float):
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")

	@abstractmethod
	def optimization_solver(self, E, gradient_f, index_to_consider, x_init):
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")

	def _init_internal_solver(self, x0):
		fun = CFunction(
			fun=self._objective_function,
			gradient=self._objective_function_gradient,
			n_dim=self.n_dim,
		)
		constraint = CConstraint.create("l1")
		constraint.center = x0
		constraint.radius = 0
		lb = self._x0.todense() if self.lb == "x0" else self.lb
		ub = self._x0.todense() if self.ub == "x0" else self.ub
		bounds = CConstraint.create("box", lb=lb, ub=ub)
		self._solver = COptimizer.create(
			"pgd-ls", fun=fun, constr=constraint, bounds=bounds, discrete=True
		)

	def create_int_list_from_x_adv(self, x_adv : CArray):
		invalid_value = 256 if self.invalid_pos == -1 else self.invalid_pos
		padding_positions = x_adv.find(x_adv == invalid_value)
		if padding_positions:
			x_adv = x_adv[:padding_positions[0]]
		if self.classifier.get_is_shifting_values():
			x_adv = x_adv - 1
		x_adv = x_adv[0,:].astype(np.uint16).tolist()[0]
		return bytearray(x_adv)

	def create_real_sample_from_adv(self, original_file_path : str, x_adv : CArray, new_file_path : str = None):
		with open(original_file_path, 'rb') as f:
			code = bytearray(f.read())
		if self.shift_values:
			x_adv = x_adv - 1
		x_adv = x_adv.tolist()
		x_adv = b''.join([bytes([i]) for i in x_adv])
		code[:len(x_adv)] = x_adv
		if new_file_path:
			with open(new_file_path, 'wb') as f:
				f.write(code)
		return code