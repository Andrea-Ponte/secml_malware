"""
.. module:: CMalConvAttackEvasion
	:synopsis: Class performs evasion attacks against malconv classifier, under different constraints.

.. moduleauthor:: Luca Demetrio <luca.demetrio@dibris.unige.it>

"""
import copy
import numpy as np
import torch

from secml.adv.attacks import CAttackEvasion
from secml.array.c_dense import CDense
from secml.optim.constraints import CConstraint
from secml.optim.function import CFunction
from secml.optim.optimizers import COptimizer
from secml.settings import SECML_PYTORCH_USE_CUDA

use_cuda = torch.cuda.is_available() and SECML_PYTORCH_USE_CUDA


class CMalConvEvasion(CAttackEvasion):
	def _objective_function_gradient(self, x):
		pass

	def _objective_function(self, x):
		pass

	def __init__(
		self,
		malconv,
		indexes_to_perturb,
		how_many,
		surrogate_data,
		surrogate_classifier=None,
		use_surrogate=False,
		iterations=1e2,
		is_debug=False,
		random_init=False,
	):
		CAttackEvasion.__init__(
			self,
			malconv,
			malconv if surrogate_classifier is None else surrogate_classifier,
			surrogate_data=surrogate_data,
			y_target=None,
		)
		self._iterations = iterations
		self.is_debug = is_debug
		self.indexes_to_perturb = indexes_to_perturb
		self._how_many = how_many
		self.confidences_ = []
		self.changes_per_iterations_ = []
		self.use_surrogate = use_surrogate
		self.random_init = random_init

	def _gradient_search(
		self,
		start_byte,
		gradient,
		embedding_bytes,
		invalid_val=np.infty,
		invalid_pos=-1,
	):
		"""Given the starting byte, the gradient and the embedding map,
		it returns a list of distances
		
		Arguments:
			start_byte {int} -- the byte that is used for searching the fittest one.
			gradient {ndarray} -- An array containing the gradient computed in start_byte
			embedding_bytes {ndarray} -- a matrix containing all the embeddings
		
		Keyword Arguments:
			invalid_val {[type]} -- Value used for indexes that are discrded during the process (default: {np.infty})
			invalid_pos {int} -- Index of invalid value, that is the index 256 (default: {-1})
		
		Returns:
			list -- matrix of distances
		"""
		distance = []
		start_emb_byte = embedding_bytes[start_byte]
		for b in embedding_bytes:
			bts = b - start_emb_byte
			gs = -gradient / torch.norm(gradient)
			s_i = torch.dot(gs, bts)
			if s_i <= 0:
				distance.append(invalid_val)
				continue
			d_i = torch.norm(b - (start_emb_byte + s_i * (-gradient)))
			distance.append(d_i)
		distance[invalid_pos] = invalid_val
		distance = torch.Tensor(distance)
		if use_cuda:
			distance = distance.cuda()
		return distance

	def _extract_window_gradient(self, gradient_f):
		"""
		Determine which components should be considered for the attack.
		Args:
			gradient_f {ndarray} -- the gradient computed on all input

		Returns:
			a list of indexes to perturb
		"""
		return (
			gradient_f[self.indexes_to_perturb, :]
			.norm(dim=-1)
			.argsort(descending=True)[: self._how_many]
			.tolist()
		)

	def _run(self, x0, y0, x_init=None):
		"""
		Tries to achieve evasion against MalConv.
		Parameters
		----------
		x0 : CArray
			Initial sample.
		y0 : int or CArray
			The true label of x0.
		x_init : CArray or None, optional
			Initialization point. If None, it is set to x0.
		Returns
		-------
		x_opt : CArray
			Evasion sample
		f_opt : float
			Value of objective function on x_opt.
		Notes
		-----
		Internally, it stores the confidences and how many iterations have been applied at each round.
		"""

		self._init_internal_solver(x0)

		if x_init is None:
			x_init = copy.copy(x0)
		self.changes_per_iterations_ = []
		self.confidences_ = []
		t = self._iterations
		zero_t = torch.zeros(8)
		if use_cuda:
			zero_t = zero_t.cuda()
		predict_fun = self._get_predict_function()
		_, current_conf = predict_fun(x_init, return_decision_function=True)
		current_conf = current_conf[1].item()
		invalid_val = torch.Tensor([np.infty])
		if use_cuda:
			invalid_val = invalid_val.cuda()
		E = self.classifier.embed(
			np.array([[i if i < 256 else 256 for i in range(2 ** 20)]]), transpose=False
		)[0][:257]
		if self.random_init:
			x_init[self.indexes_to_perturb] = CDense(
				torch.randint(255, (1, len(self.indexes_to_perturb)))
			)
		if self.is_debug:
			print("> Beginning new sample evasion...")
		classifier = (
			self.surrogate_classifier if self.use_surrogate else self.classifier
		)
		gradient_f = classifier.compute_embedding_gradient(x_init)
		index_to_consider = np.array(self.indexes_to_perturb)[
			self._extract_window_gradient(gradient_f)
		]
		while t and current_conf > 0.5:
			if self.is_debug:
				print("> Evasion iteration:\t{}".format(t))
				print("> Current confidence:\t{}".format(current_conf))
			how_many_invalid = 0
			gradient_f = classifier.compute_embedding_gradient(x_init)
			for i in index_to_consider:
				if how_many_invalid > len(index_to_consider):
					return current_conf
				gradient_f_i = gradient_f[i]
				x_i = x_init[i].tondarray().ravel().item()
				if torch.equal(gradient_f_i, zero_t):
					how_many_invalid = how_many_invalid + 1
					continue
				distances = self._gradient_search(
					x_i, gradient_f_i, E, invalid_val=invalid_val
				)
				_, byte_to_choose = torch.min(distances, dim=0)
				if torch.equal(distances[byte_to_choose], invalid_val):
					how_many_invalid = how_many_invalid + 1
					continue
				x_init[i] = byte_to_choose.item()
				_, current_conf = predict_fun(x_init, return_decision_function=True)
				current_conf = current_conf[1].item()
				self.confidences_.append(current_conf)
			self.changes_per_iterations_.append(
				len(self.indexes_to_perturb) - how_many_invalid
			)
			t = t - 1
			if self.is_debug:
				print(
					"> invalid values:\t{}/{}".format(
						how_many_invalid, len(self.indexes_to_perturb)
					)
				)
				print("> Shifted confidence:\t{}".format(current_conf))
			if how_many_invalid == len(self.indexes_to_perturb):
				break
		return x_init, current_conf

	def _get_predict_function(self):
		predict_fun = (
			self.surrogate_classifier.predict
			if self.use_surrogate
			else self.classifier.predict
		)
		return predict_fun

	def _init_internal_solver(self, x0):
		fun = CFunction(
			fun=self._objective_function,
			gradient=self._objective_function_gradient,
			n_dim=self.n_dim,
		)
		constraint = CConstraint.create("l1")
		constraint.center = x0
		constraint.radius = 0
		lb = self._x0.todense() if self.lb == "x0" else self.lb
		ub = self._x0.todense() if self.ub == "x0" else self.ub
		bounds = CConstraint.create("box", lb=lb, ub=ub)
		self._solver = COptimizer.create(
			"pgd-ls", fun=fun, constr=constraint, bounds=bounds, discrete=True
		)
