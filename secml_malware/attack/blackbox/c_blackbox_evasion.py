import copy
from abc import abstractmethod

from scipy.optimize import minimize
from secml.adv.attacks import CAttackEvasion
from secml.array import CArray
from secml.data import CDataset
from secml.ml.classifiers import CClassifier
from secml.optim.constraints import CConstraint
from secml.optim.function import CFunction
from secml.optim.optimizers import COptimizer
from secml_malware.attack.blackbox.c_wrapper_phi import CWrapperPhi


class CBlackBoxEvasion(CAttackEvasion):

	def _objective_function_gradient(self, x):
		pass

	def _objective_function(self, x):
		pass

	def __init__(
			self,
			model_wrapper: CWrapperPhi,
			indexes_to_perturb: list,
			iterations: int = 100,
			is_debug: bool = False,
			random_init: bool = False,
			threshold: float = 0.5,
			penalty_regularizer: float = 0,
	):
		CAttackEvasion.__init__(
			self,
			model_wrapper.classifier,
			model_wrapper.classifier,
			surrogate_data=CDataset(CArray([[0], [1]]), CArray([0, 1])),
			y_target=None,
		)
		self.iterations = iterations
		self.is_debug = is_debug
		self.indexes_to_perturb = indexes_to_perturb
		self.confidences_ = []
		self.changes_per_iterations_ = []
		self.model_wrapper = model_wrapper
		self.random_init = random_init

		self.threshold = threshold
		self.penalty_regularizer = penalty_regularizer

	def _init_internal_solver(self, x0: CArray):
		fun = CFunction(
			fun=self._objective_function,
			gradient=self._objective_function_gradient,
			n_dim=self.n_dim,
		)
		constraint = CConstraint.create("l1")
		constraint.center = x0
		constraint.radius = 0
		lb = x0.todense() if self.lb == "x0" else self.lb
		ub = x0.todense() if self.ub == "x0" else self.ub
		bounds = CConstraint.create("box", lb=lb, ub=ub)
		self._solver = COptimizer.create(
			"pgd-ls", fun=fun, constr=constraint, bounds=bounds, discrete=True
		)

	def _run(self, x0, y0, x_init=None):
		self._init_internal_solver(x0)

		if x_init is None:
			x_init = copy.copy(x0)

		_, current_conf = self.model_wrapper.predict(x_init, return_decision_function=True)
		current_conf = current_conf[1].item()
		self.confidences_ = [current_conf]
		if self.is_debug:
			print(f'> Original Confidence: {current_conf}')
			print("> Beginning new sample evasion...")

		bounds = self.create_bounds()
		best_t = minimize(self.compute_best_t, args=[x_init], bounds=bounds, options={'maxiter': self.iterations})

		x_init = self.apply_feasible_manipulations(best_t, x_init)
		_, current_conf = self.model_wrapper.predict(x_init, return_decision_function=True)
		current_conf = current_conf[1].item()
		self.confidences_.append(current_conf)
		if self.is_debug:
			print(f'>AFTER INVERSION, CONFIDENCE SCORE: {current_conf}')
		return x_init, current_conf

	def compute_best_t(self, t: CArray, original_x: CArray):
		candidate = self.apply_feasible_manipulations(t, original_x)
		penalty_term = self.compute_penalty_term(original_x, candidate)
		score = self.score_step(candidate, penalty_term)
		self.confidences_.append(score)
		return score

	@abstractmethod
	def score_step(self, x, penalty_term: float) -> float:
		raise NotImplementedError("This class is abstract, you should implement this function!")

	@abstractmethod
	def create_bounds(self) -> list:
		raise NotImplementedError("This class is abstract, you should implement this function!")

	@abstractmethod
	def compute_penalty_term(self, original_x, adv_x, par: float) -> float:
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")

	@abstractmethod
	def apply_feasible_manipulations(self, t: CArray, x: CArray) -> CArray:
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")
