import copy
from abc import abstractmethod
import numpy as np
from scipy.optimize import differential_evolution
from secml.adv.attacks import CAttackEvasion
from secml.array import CArray
from secml.data import CDataset
from secml.optim.constraints import CConstraint
from secml.optim.function import CFunction
from secml.optim.optimizers import COptimizer
from secml_malware.attack.blackbox.c_wrapper_phi import CWrapperPhi


class CBlackBoxEvasion(CAttackEvasion):

	def _objective_function_gradient(self, x):
		pass

	def _objective_function(self, x):
		pass

	def __init__(
			self,
			model_wrapper: CWrapperPhi,
			indexes_to_perturb: list,
			iterations: int = 100,
			is_debug: bool = False,
			threshold: float = 0.5,
			penalty_regularizer: float = 0
	):
		CAttackEvasion.__init__(
			self,
			model_wrapper.classifier,
			model_wrapper.classifier,
			surrogate_data=CDataset(CArray([[0], [1]]), CArray([0, 1])),
			y_target=None,
		)
		self.iterations = iterations
		self.is_debug = is_debug
		self.indexes_to_perturb = indexes_to_perturb
		self.confidences_ = []
		self.changes_per_iterations_ = []
		self.model_wrapper = model_wrapper
		self.threshold = threshold
		self.penalty_regularizer = penalty_regularizer

	def _init_internal_solver(self, x0: CArray):
		fun = CFunction(
			fun=self._objective_function,
			gradient=self._objective_function_gradient,
			n_dim=self.n_dim,
		)
		constraint = CConstraint.create("l1")
		constraint.center = x0
		constraint.radius = 0
		lb = x0.todense() if self.lb == "x0" else self.lb
		ub = x0.todense() if self.ub == "x0" else self.ub
		bounds = CConstraint.create("box", lb=lb, ub=ub)
		self._solver = COptimizer.create(
			"pgd-ls", fun=fun, constr=constraint, bounds=bounds, discrete=True
		)

	def run(self, x, y, ds_init=None, *args, **kargs):
		x = CArray(x).atleast_2d()
		y = CArray(y).atleast_2d()
		x_init = None if ds_init is None else CArray(ds_init.X).atleast_2d()

		# only consider samples that can be manipulated
		v = self.is_attack_class(y)
		idx = CArray(v.find(v)).ravel()
		# print(v, idx)

		# number of modifiable samples
		n_mod_samples = idx.size

		adv_ds = CDataset(x.deepcopy(), y.deepcopy())

		# If dataset is sparse, set the proper attribute
		if x.issparse is True:
			self._issparse = True

		# array in which the value of the optimization function are stored
		fs_opt = CArray.zeros(n_mod_samples, )

		for i in range(n_mod_samples):
			k = idx[i].item()  # idx of sample that can be modified

			xi = x[k, :] if x_init is None else x_init[k, :]
			x_opt, f_opt = self._run(x[k, :], y[k], x_init=xi, *args, **kargs)

			self.logger.info(
				"Point: {:}/{:}, dmax:{:}, f(x):{:}, eval:{:}/{:}".format(k, x.shape[0], self._dmax, f_opt, self.f_eval,
																		  self.grad_eval))
			if x_opt.shape[-1] > adv_ds.X.shape[-1]:
				# Need to resize the whole adv dataset, since CDataset can't deal with varying vector sizes
				new_length = x_opt.shape[-1]
				adv_ds.X = adv_ds.X.resize((adv_ds.X.shape[0], new_length), 256)
			adv_ds.X[k, :] = x_opt
			fs_opt[i] = f_opt

		y_pred, scores = self.classifier.predict(
			adv_ds.X, return_decision_function=True)

		y_pred = CArray(y_pred)

		# Return the mean objective function value on the evasion points (
		# computed from the outputs of the surrogate classifier)
		f_obj = fs_opt.mean()

		return y_pred, scores, adv_ds, f_obj

	def _run(self, x0, y0, x_init=None):
		self._init_internal_solver(x0)

		if x_init is None:
			x_init = copy.copy(x0)

		_, current_conf = self.model_wrapper.predict(x_init, return_decision_function=True)
		current_conf = current_conf[1].item()
		self.confidences_ = [current_conf]
		if self.is_debug:
			print(f'> Original Confidence: {current_conf}')
			print("> Beginning new sample evasion...")

		bounds = self.create_bounds()
		minimization_results = differential_evolution(self.compute_best_t, args=[x_init], bounds=bounds,
													  maxiter=self.iterations, popsize=10)

		x_init = self.apply_feasible_manipulations(minimization_results.x, x_init)
		_, current_conf = self.model_wrapper.predict(x_init, return_decision_function=True)
		current_conf = current_conf[1].item()
		self.confidences_.append(current_conf)
		if self.is_debug:
			print(f'>AFTER INVERSION, CONFIDENCE SCORE: {current_conf}')
		return CArray([np.frombuffer(x_init, dtype=np.uint8)]), current_conf

	def compute_best_t(self, t, original_x):
		candidate = self.apply_feasible_manipulations(t, original_x)
		penalty_term = self.compute_penalty_term(original_x, candidate, self.penalty_regularizer)
		score = self.score_step(candidate, penalty_term)
		self.confidences_.append(score)
		return score

	@abstractmethod
	def score_step(self, x, penalty_term: float) -> float:
		raise NotImplementedError("This class is abstract, you should implement this function!")

	@abstractmethod
	def create_bounds(self) -> list:
		raise NotImplementedError("This class is abstract, you should implement this function!")

	@abstractmethod
	def compute_penalty_term(self, original_x, adv_x, par: float) -> float:
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")

	@abstractmethod
	def apply_feasible_manipulations(self, t: CArray, x: CArray) -> CArray:
		raise NotImplementedError("This method is abstract, you should implement it somewhere else!")
