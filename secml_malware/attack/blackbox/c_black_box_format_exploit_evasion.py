from secml_malware.attack.blackbox.c_blackbox_evasion import CBlackBoxEvasion
from secml_malware.attack.blackbox.c_wrapper_phi import CWrapperPhi
from secml_malware.utils.extend_pe import shift_section_by, shift_pe_header_by


class CBlackBoxFormatExploitEvasion(CBlackBoxEvasion):
	def __init__(
			self,
			model_wrapper: CWrapperPhi,
			preferable_extension_amount: int = 0x200,
			pe_header_extension: int = 0x200,
			iterations: int = 100,
			is_debug: bool = False,
			random_init: bool = False,
			threshold: float = 0.5,
			penalty_regularizer: float = 0,
	):
		super(CBlackBoxFormatExploitEvasion, self).__init__(model_wrapper, [], iterations, is_debug, random_init,
															threshold, penalty_regularizer)

		self.preferable_extension_amount = preferable_extension_amount
		self.pe_header_extension = pe_header_extension

	def _craft_perturbed_c_array(self, x0):
		x_init, index_to_perturb_sections = shift_section_by(x0,
															 preferable_extension_amount=self.preferable_extension_amount)
		x_init, index_to_perturb_pe = shift_pe_header_by(x_init, preferable_extension_amount=self.pe_header_extension)
		indexes_to_perturb = index_to_perturb_pe + [i + len(index_to_perturb_pe) for i in
													index_to_perturb_sections]
		return x_init, indexes_to_perturb

	def create_bounds(self) -> list:
		return [[0,1] for _ in self.indexes_to_perturb]

	def compute_penalty_term(self, original_x, adv_x, par: float) -> float:
		return par * abs(len(adv_x) - len(original_x))

	def apply_feasible_manipulations(self, t, x):
		x[self.indexes_to_perturb] = t
		return x

	def score_step(self, x, penalty_term: float) -> float:
		confidence = self.model_wrapper.predict(x, return_decision_function=True)
		confidence = confidence[0,1].item()
		return confidence + penalty_term

	def _run(self, x0, y0, x_init=None):
		x0, indexes_to_perturb = self._craft_perturbed_c_array(x0)
		super(CBlackBoxFormatExploitEvasion, self)._run(x0, y0, x_init)
