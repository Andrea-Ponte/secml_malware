from secml_malware.attack import CEnd2EndMalwareEvasion
import lief


class CInterSectionEvasion(CEnd2EndMalwareEvasion):
	"""Construct evasion object for messing with slack space.
	"""

	def __init__(
		self,
		end2end_model,
		surrogate_data,
		how_many,
		surrogate_classifier=None,
		use_surrogate=False,
		iterations=100.0,
		is_debug=False,
		random_init=False,
	):
		"""Class constructor.

		Arguments:
			malconv {CClassifierMalConvPyTorch} -- The classifier to evade
			surrogate_data {CDataset} -- data used for the surrogate (if any)
			how_many {int} -- How many index to perturb. None means use all indexes

		Keyword Arguments:
			surrogate_classifier {CClassifierMalConvPyTorch} -- Surrogate classifier, if any (default: {None})
			use_surrogate {bool} -- Specify if should use the surrogate instead of real classifier (default: {False})
			iterations {float} -- How many iterations for the attack (default: {100.0})
			is_debug {bool} -- If true, it will print on console additional information duringthe attack (default: {False})
			random_init {bool} -- Randomize the bytes located at the specified indexes before starting the attack(default: {False})

		Returns:
			CGreedyEvasion -- the evasion object
		"""
		super(CInterSectionEvasion, self).__init__(
			end2end_model,
			[],
			how_many,
			iterations=iterations,
			is_debug=is_debug,
			random_init=random_init,
		)

	def _run(self, x0, y0, x_init=None):
		raise NotImplementedError('This attack need to be properly implemented in the nex release of secml_malware')
		# self.indexes_to_perturb = []
		# stop_index = x0.find(x0 == 256)
		# if not stop_index:
		# 	code = x0.tolist()[0]
		# else:
		# 	code = x0.tolist()[0][: stop_index[0]]
		# exe = lief.PE.parse(code)
		# for s in exe.sections:
		# 	physical = s.pointerto_raw_data + s.SizeOfRawData
		# 	virtual = s.PointerToRawData + s.Misc_VirtualSize
		# 	if physical > virtual:
		# 		self.indexes_to_perturb.extend(range(virtual, physical))
		# return super(CInterSectionEvasion, self)._run(x0, y0, x_init=x_init)
