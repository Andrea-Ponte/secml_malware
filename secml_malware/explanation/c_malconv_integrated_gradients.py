from secml.explanation import CExplainerIntegratedGradients
from secml.array import CArray
from secml.core.type_utils import is_int


class CMalConvIntegratedGradients(CExplainerIntegratedGradients):
	def explain(self, x, reference=None, m=50, classes="all"):
		"""Computes the explanation for input sample.

		Arguments:
			x {CArray} -- Input sample.
		Keyword Arguments:
			reference {CArray} -- The reference sample.
			Must have the same shape of input sample. If None, a all-zeros sample will be used.
		m : {int} -- The number of steps for linear interpolation. Default 50.
		classes : {CArray} -- CArray with the classes wrt the attributions should be computed.
		Can be a single class (int). If 'str' (default), all training classes will be considered.

		Returns
		attributions {CArray} -- Attributions (weight of each feature) for input sample.
		Will be a 2D array with the attributions computed wrt each class in `classes` for each row.

		"""
		if reference is None:
			# Use default reference values if reference is not specified
			reference = CArray.zeros(shape=x.shape, dtype=x.dtype)

		x = x.atleast_2d()

		if classes == "all":  # Consider all training classes
			classes = self.clf.classes
		elif is_int(classes):
			classes = [classes]
		elif not isinstance(classes, CArray):
			raise TypeError(
				"`classes` can be a CArray with the list of "
				"classes, a single class id or 'all'"
			)

		# Compute the linear interpolation from reference to input
		ret = self.linearly_interpolate(x, reference, m)
		emb_x = self._clf.embed(x.tondarray(), transpose=False)
		emb_x = emb_x.squeeze()
		emb_baseline = self._clf.embed(reference.tondarray(), transpose=False)
		emb_baseline = emb_baseline.squeeze()
		attr = CArray.empty(shape=(0, x.shape[1]), dtype=x.dtype)

		# Compute the Riemman approximation of the integral
		riemman_approx = CArray.zeros(emb_x.shape, dtype=x.dtype)
		for i in range(len(ret)):
			riemman_approx += self.clf.gradient_f_x(ret[i], sum_embedding=False)
		diff = emb_x - emb_baseline
		a = CArray(diff.detach().numpy()) * (1.0 / m) * riemman_approx
		a = a.mean(axis=1).transpose()
		self.logger.debug("Attributions for class {:}:\n{:}".format(1, a))

		# Checks prop 1: attr should adds up to the difference between
		# the score at the input and that at the reference
		self.check_attributions(x, reference, 1, a)
		attr = attr.append(-a, axis=0)
		attr = attr.append(a, axis=0)
		return attr
